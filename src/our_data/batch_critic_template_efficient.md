<|im_start|>system
# Task
Evaluate the performance of the input prompt, identify the parts of the prompt used for predictions, and offer feedback for improvement.

# Step-by-Step Instructions:

1. **Identification of Prompt Parts**:
   - Review the prompt and the model’s output.
   - Identify specific sections, guidelines, or criteria in the prompt that were used by the model to make the prediction.
   - Use the keys of the prompt json and separate each key using `>` to form `prompt_references`.
   - Provide these sections as `prompt_references`.
   - Ensure the `prompt_references` are valid and not fake.

2. **Feedback for Improvement (prompt_feedback)**:
   - First state the input `input`, expected output `ground_truth` and `prediction` using the given prompt. Example: Input: '<input text>', Expected Output: '<ground_truth>', Prediction: '<prediction>'.
   - Analyze any discrepancies between the model’s outputs and the expected outputs.
   - Offer constructive feedback on what might have gone wrong and suggest changes to the prompt to improve accuracy.
   - Provide specific suggestions for altering the prompt to correct these errors.
   - Include `prompt_references` to indicate the sections of the prompt that may need to be updated.

# Input Format:

**Example Prompt**

```json
{"<Heading 1>":{"body": "<body>","<Heading 1.1>":{"body": "<body>",...},"<Heading 1.2>":{"body": "<body>","Examples":["<example 1>",....],"<Heading 1.2.1>":{"body": "<body>","1.": {"body": "<instruction>","Examples":["<example 1>","<example 2>",.....]},"2.":...},"<Heading 1.2.2>":{"body": "<body>"}...}...},"<Heading 2>":{"body": "<body>"}...}
```

**Example Batch Evaluations**

```json
{"prompt": "The current prompt being used.","input_data": [{"id": "<unique id>","input": "<input text>","prediction": "<output generated by the model>","ground_truth": "<correct output>"},...]}
```

# Output Format:

```json
[{"id": "<unique id>","prompt_feedback": "<feedback for improvement>","prompt_references": ["Heading 1> Heading 1.2> Heading 1.2.1> body","Heading 1> Heading 1.2> Heading 1.2.1> 2.> body","Heading 1> Heading 1.2> body","Heading 2> body>"]},...]
```
<|im_end|>
<|im_start|>user
**Input Prompt**

```json
{parsed_prompt}
```

**Batch Evaluations**

```json
{batch_evaluation}
```

# Reminder
* `prompt_feedback` must explicitly suggest how can be the input prompt can be improved to generate correct predictions. It can consist of following:
  - Rephrasing by clarifying language
  - Repharsing by adding details or enhancing clarity
  - Compacting information by removing redundant information
  - Changing tone and mainting consistency
  - Adding illustrative and informative examples
  - Deleting confusing or redundant examples and maintaing effective examples
  - Ensuring essential information
  - Arrange sections in a logical sequence that guides the reader through the instructions
  - Any other type of feedback
* `prompt_feedback` should not limit to only adding more examples. It can suggestion multiple ways to improve the prompt.
<|im_end|>
<|im_start|>assistant
```json